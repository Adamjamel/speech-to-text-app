const OpenAI = require('openai');
const fs = require('fs');
const path = require('path');

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

class SpeechService {
  async transcribeAudio(filePath) {
    try {
      console.log('üìù D√©but de la transcription pour:', filePath);
      
      const transcription = await openai.audio.transcriptions.create({
        file: fs.createReadStream(filePath),
        model: "whisper-1",
        language: "fr", // Fran√ßais par d√©faut, peut √™tre modifi√©
        response_format: "json",
        temperature: 0.2
      });

      console.log('‚úÖ Transcription termin√©e');
      return {
        text: transcription.text,
        duration: transcription.duration || null
      };
    } catch (error) {
      console.error('‚ùå Erreur lors de la transcription:', error.message);
      throw new Error(`Erreur de transcription: ${error.message}`);
    }
  }

  async transcribeWithTimestamps(filePath) {
    try {
      const transcription = await openai.audio.transcriptions.create({
        file: fs.createReadStream(filePath),
        model: "whisper-1",
        response_format: "verbose_json",
        timestamp_granularities: ["word"]
      });

      return {
        text: transcription.text,
        words: transcription.words,
        duration: transcription.duration
      };
    } catch (error) {
      console.error('‚ùå Erreur lors de la transcription avec timestamps:', error.message);
      throw new Error(`Erreur de transcription: ${error.message}`);
    }
  }
}

module.exports = new SpeechService();