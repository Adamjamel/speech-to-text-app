// const OpenAI = require('openai');
// const fs = require('fs');
// const path = require('path');

// const openai = new OpenAI({
//   apiKey: process.env.OPENAI_API_KEY
// });

// class SpeechService {
//   async transcribeAudio(filePath) {
//     try {
//       console.log('üìù D√©but de la transcription pour:', filePath);
      
//       const transcription = await openai.audio.transcriptions.create({
//         file: fs.createReadStream(filePath),
//         model: "whisper-1",
//         language: "fr", // Fran√ßais par d√©faut, peut √™tre modifi√©
//         response_format: "json",
//         temperature: 0.2
//       });

//       console.log('‚úÖ Transcription termin√©e');
//       return {
//         text: transcription.text,
//         duration: transcription.duration || null
//       };
//     } catch (error) {
//       console.error('‚ùå Erreur lors de la transcription:', error.message);
//       throw new Error(`Erreur de transcription: ${error.message}`);
//     }
//   }

//   async transcribeWithTimestamps(filePath) {
//     try {
//       const transcription = await openai.audio.transcriptions.create({
//         file: fs.createReadStream(filePath),
//         model: "whisper-1",
//         response_format: "verbose_json",
//         timestamp_granularities: ["word"]
//       });

//       return {
//         text: transcription.text,
//         words: transcription.words,
//         duration: transcription.duration
//       };
//     } catch (error) {
//       console.error('‚ùå Erreur lors de la transcription avec timestamps:', error.message);
//       throw new Error(`Erreur de transcription: ${error.message}`);
//     }
//   }
// }

// module.exports = new SpeechService();
const { spawn } = require('child_process');
const path = require('path');

class SpeechService {
  async transcribeAudio(filePath) {
    try {
      console.log('üìù D√©but de la transcription locale pour:', filePath);

      const result = await this.runPythonScript('transcribe.py', filePath);
      return {
        text: result,
        duration: null // Tu peux calculer la dur√©e avec ffmpeg si n√©cessaire
      };
    } catch (error) {
      console.error('‚ùå Erreur de transcription locale:', error);
      throw new Error(`Erreur de transcription locale: ${error}`);
    }
  }

  async transcribeWithTimestamps(filePath) {
    try {
      const result = await this.runPythonScript('transcribe_with_timestamps.py', filePath);
      const parsed = JSON.parse(result);

      return {
        text: parsed.text,
        words: parsed.segments?.flatMap(seg => seg.words) || [],
        duration: parsed.segments?.slice(-1)[0]?.end || null
      };
    } catch (error) {
      console.error('‚ùå Erreur de transcription avec timestamps:', error);
      throw new Error(`Erreur de transcription avec timestamps locale: ${error}`);
    }
  }

  runPythonScript(scriptName, filePath) {
    return new Promise((resolve, reject) => {
      const scriptPath = path.join(__dirname, '../../', scriptName);
      const process = spawn('python3', [scriptPath, filePath]);

      let output = '';
      let errorOutput = '';

      process.stdout.on('data', (data) => output += data.toString());
      process.stderr.on('data', (data) => errorOutput += data.toString());

      process.on('close', (code) => {
        if (code === 0) {
          resolve(output.trim());
        } else {
          reject(errorOutput || `Script termin√© avec le code ${code}`);
        }
      });
    });
  }
}

module.exports = new SpeechService();
